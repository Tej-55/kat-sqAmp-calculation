{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchtext==0.17.2 torch torchvision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T16:01:30.535849Z","iopub.execute_input":"2025-04-05T16:01:30.536269Z","iopub.status.idle":"2025-04-05T16:03:59.482225Z","shell.execute_reply.started":"2025-04-05T16:01:30.536233Z","shell.execute_reply":"2025-04-05T16:03:59.481237Z"}},"outputs":[{"name":"stdout","text":"Collecting torchtext==0.17.2\n  Using cached torchtext-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.17.2) (4.67.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.17.2) (2.32.3)\nCollecting torch\n  Using cached torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.17.2) (1.26.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.2.0 (from torch)\n  Using cached triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision\n  Using cached torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n  Using cached torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n  Using cached torchvision-0.20.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n  Using cached torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n  Using cached torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n  Using cached torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n  Using cached torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\nINFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n  Using cached torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.17.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.17.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.17.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.17.2) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.17.2) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.17.2) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.17.2) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.17.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.17.2) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.17.2) (2025.1.31)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchtext==0.17.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchtext==0.17.2) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchtext==0.17.2) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchtext==0.17.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchtext==0.17.2) (2024.2.0)\nUsing cached torchtext-0.17.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\nUsing cached torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\nUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\nUsing cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\nUsing cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\nUsing cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\nDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchtext\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu121\n    Uninstalling torch-2.5.1+cu121:\n      Successfully uninstalled torch-2.5.1+cu121\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.20.1+cu121\n    Uninstalling torchvision-0.20.1+cu121:\n      Successfully uninstalled torchvision-0.20.1+cu121\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\ntorchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchtext-0.17.2 torchvision-0.17.2 triton-2.2.0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install triton==3.2.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T16:03:59.483706Z","iopub.execute_input":"2025-04-05T16:03:59.484166Z","iopub.status.idle":"2025-04-05T16:04:11.869827Z","shell.execute_reply.started":"2025-04-05T16:03:59.484132Z","shell.execute_reply":"2025-04-05T16:04:11.868844Z"}},"outputs":[{"name":"stdout","text":"Collecting triton==3.2.0\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton\n  Attempting uninstall: triton\n    Found existing installation: triton 2.2.0\n    Uninstalling triton-2.2.0:\n      Successfully uninstalled triton-2.2.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorch 2.2.2 requires triton==2.2.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.12\", but you have triton 3.2.0 which is incompatible.\ntorchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed triton-3.2.0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!git clone --branch kan-trial https://github.com/Tej-55/GSoC-TITANS.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T16:00:41.713410Z","iopub.execute_input":"2025-04-05T16:00:41.713692Z","iopub.status.idle":"2025-04-05T16:00:44.669255Z","shell.execute_reply.started":"2025-04-05T16:00:41.713671Z","shell.execute_reply":"2025-04-05T16:00:44.668362Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'GSoC-TITANS'...\nremote: Enumerating objects: 282, done.\u001b[K\nremote: Counting objects: 100% (182/182), done.\u001b[K\nremote: Compressing objects: 100% (129/129), done.\u001b[K\nremote: Total 282 (delta 93), reused 131 (delta 50), pack-reused 100 (from 1)\u001b[K\nReceiving objects: 100% (282/282), 61.44 MiB | 32.15 MiB/s, done.\nResolving deltas: 100% (132/132), done.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"%cd GSoC-TITANS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T16:01:07.637096Z","iopub.execute_input":"2025-04-05T16:01:07.637513Z","iopub.status.idle":"2025-04-05T16:01:07.644551Z","shell.execute_reply.started":"2025-04-05T16:01:07.637474Z","shell.execute_reply":"2025-04-05T16:01:07.643608Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/GSoC-TITANS\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install -e ./rational_kat_cu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T16:01:09.862335Z","iopub.execute_input":"2025-04-05T16:01:09.862603Z","iopub.status.idle":"2025-04-05T16:01:24.802037Z","shell.execute_reply.started":"2025-04-05T16:01:09.862583Z","shell.execute_reply":"2025-04-05T16:01:24.800971Z"}},"outputs":[{"name":"stdout","text":"Obtaining file:///kaggle/working/GSoC-TITANS/rational_kat_cu\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nInstalling collected packages: kat_rational\n  Running setup.py develop for kat_rational\nSuccessfully installed kat_rational-0.4\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import triton\nprint(triton.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T16:04:11.871938Z","iopub.execute_input":"2025-04-05T16:04:11.872333Z","iopub.status.idle":"2025-04-05T16:04:11.962543Z","shell.execute_reply.started":"2025-04-05T16:04:11.872301Z","shell.execute_reply":"2025-04-05T16:04:11.961708Z"}},"outputs":[{"name":"stdout","text":"3.2.0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!ls ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T16:04:11.963615Z","iopub.execute_input":"2025-04-05T16:04:11.964011Z","iopub.status.idle":"2025-04-05T16:04:12.088473Z","shell.execute_reply.started":"2025-04-05T16:04:11.963975Z","shell.execute_reply":"2025-04-05T16:04:12.087369Z"}},"outputs":[{"name":"stdout","text":"data\t\t\t rational_kat_cu  t5_output\t  titans_output\nkaggle_run_t5.ipynb\t README.md\t  titans\t  utils\nkaggle_run_titans.ipynb  t5_main.py\t  titans_main.py\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"!python -m torch.distributed.launch --nproc_per_node=2 t5_main.py --num_epochs=8 --batch_size=8 --model_dir t5_KAT_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T16:07:14.974717Z","iopub.execute_input":"2025-04-05T16:07:14.975181Z","iopub.status.idle":"2025-04-05T17:20:51.184752Z","shell.execute_reply.started":"2025-04-05T16:07:14.975144Z","shell.execute_reply":"2025-04-05T17:20:51.183582Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated\nand will be removed in future. Use torchrun.\nNote that --use-env is set by default in torchrun.\nIf your script expects `--local-rank` argument to be set, please\nchange it to read from `os.environ['LOCAL_RANK']` instead. See \nhttps://pytorch.org/docs/stable/distributed.html#launch-utility for \nfurther instructions\n\n  warnings.warn(\n[2025-04-05 16:07:16,481] torch.distributed.run: [WARNING] \n[2025-04-05 16:07:16,481] torch.distributed.run: [WARNING] *****************************************\n[2025-04-05 16:07:16,481] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n[2025-04-05 16:07:16,481] torch.distributed.run: [WARNING] *****************************************\n2025-04-05 16:07:20.677183: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-05 16:07:20.677180: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-05 16:07:20.700556: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-04-05 16:07:20.700633: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-04-05 16:07:20.709085: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-04-05 16:07:20.709245: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n| distributed init (rank 0): env://\n| distributed init (rank 1): env://\nconfig.json: 100%|█████████████████████████| 1.21k/1.21k [00:00<00:00, 6.98MB/s]\nmodel.safetensors: 100%|██████████████████████| 242M/242M [00:01<00:00, 221MB/s]\ngeneration_config.json: 100%|███████████████████| 147/147 [00:00<00:00, 860kB/s]\nNumber of training batches: 778\nNumber of validation batches: 98\nNumber of test batches: 98\nUsing device: cuda:0\nEpoch 1/8:   0%|                                        | 0/778 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\nEpoch 1/8:   6%|█▉                             | 49/778 [00:29<06:21,  1.91it/s]Epoch 1/8 | Batch 50/778 | Loss: 1.0255\nEpoch 1/8:  13%|███▉                           | 99/778 [00:55<06:03,  1.87it/s]Epoch 1/8 | Batch 100/778 | Loss: 0.7261\nEpoch 1/8:  19%|█████▋                        | 149/778 [01:23<05:54,  1.77it/s]Epoch 1/8 | Batch 150/778 | Loss: 0.3897\nEpoch 1/8:  26%|███████▋                      | 199/778 [01:52<05:43,  1.69it/s]Epoch 1/8 | Batch 200/778 | Loss: 0.4250\nEpoch 1/8:  32%|█████████▌                    | 249/778 [02:23<05:39,  1.56it/s]Epoch 1/8 | Batch 250/778 | Loss: 0.4121\nEpoch 1/8:  38%|███████████▌                  | 299/778 [02:55<05:01,  1.59it/s]Epoch 1/8 | Batch 300/778 | Loss: 0.2861\nEpoch 1/8:  45%|█████████████▍                | 349/778 [03:26<04:29,  1.59it/s]Epoch 1/8 | Batch 350/778 | Loss: 0.1640\nEpoch 1/8:  51%|███████████████▍              | 399/778 [03:58<04:00,  1.57it/s]Epoch 1/8 | Batch 400/778 | Loss: 0.2606\nEpoch 1/8:  58%|█████████████████▎            | 449/778 [04:30<03:27,  1.59it/s]Epoch 1/8 | Batch 450/778 | Loss: 0.3069\nEpoch 1/8:  64%|███████████████████▏          | 499/778 [05:01<02:55,  1.59it/s]Epoch 1/8 | Batch 500/778 | Loss: 0.2645\nEpoch 1/8:  71%|█████████████████████▏        | 549/778 [05:33<02:25,  1.58it/s]Epoch 1/8 | Batch 550/778 | Loss: 0.1660\nEpoch 1/8:  77%|███████████████████████       | 599/778 [06:05<01:53,  1.58it/s]Epoch 1/8 | Batch 600/778 | Loss: 0.2300\nEpoch 1/8:  83%|█████████████████████████     | 649/778 [06:37<01:22,  1.57it/s]Epoch 1/8 | Batch 650/778 | Loss: 0.1518\nEpoch 1/8:  90%|██████████████████████████▉   | 699/778 [07:08<00:50,  1.58it/s]Epoch 1/8 | Batch 700/778 | Loss: 0.1655\nEpoch 1/8:  96%|████████████████████████████▉ | 749/778 [07:40<00:18,  1.58it/s]Epoch 1/8 | Batch 750/778 | Loss: 0.1421\nEpoch 1/8: 100%|██████████████████████████████| 778/778 [07:59<00:00,  1.62it/s]\nValidation: 100%|███████████████████████████████| 98/98 [00:19<00:00,  5.11it/s]\nEpoch 1/8\nTrain loss: 0.3419\nValidation loss: 0.1031\n--------------------------------------------------\nEpoch 2/8:   6%|█▉                             | 49/778 [00:30<07:43,  1.57it/s]Epoch 2/8 | Batch 50/778 | Loss: 0.0902\nEpoch 2/8:  13%|███▉                           | 99/778 [01:02<07:10,  1.58it/s]Epoch 2/8 | Batch 100/778 | Loss: 0.1115\nEpoch 2/8:  19%|█████▋                        | 149/778 [01:34<06:42,  1.56it/s]Epoch 2/8 | Batch 150/778 | Loss: 0.1011\nEpoch 2/8:  26%|███████▋                      | 199/778 [02:06<06:09,  1.57it/s]Epoch 2/8 | Batch 200/778 | Loss: 0.0836\nEpoch 2/8:  32%|█████████▌                    | 249/778 [02:38<05:40,  1.56it/s]Epoch 2/8 | Batch 250/778 | Loss: 0.1338\nEpoch 2/8:  38%|███████████▌                  | 299/778 [03:10<05:04,  1.57it/s]Epoch 2/8 | Batch 300/778 | Loss: 0.1159\nEpoch 2/8:  45%|█████████████▍                | 349/778 [03:41<04:30,  1.59it/s]Epoch 2/8 | Batch 350/778 | Loss: 0.1588\nEpoch 2/8:  51%|███████████████▍              | 399/778 [04:13<03:58,  1.59it/s]Epoch 2/8 | Batch 400/778 | Loss: 0.0887\nEpoch 2/8:  58%|█████████████████▎            | 449/778 [04:44<03:28,  1.58it/s]Epoch 2/8 | Batch 450/778 | Loss: 0.1172\nEpoch 2/8:  64%|███████████████████▏          | 499/778 [05:16<02:56,  1.58it/s]Epoch 2/8 | Batch 500/778 | Loss: 0.0708\nEpoch 2/8:  71%|█████████████████████▏        | 549/778 [05:48<02:25,  1.58it/s]Epoch 2/8 | Batch 550/778 | Loss: 0.0862\nEpoch 2/8:  77%|███████████████████████       | 599/778 [06:20<01:54,  1.57it/s]Epoch 2/8 | Batch 600/778 | Loss: 0.0952\nEpoch 2/8:  83%|█████████████████████████     | 649/778 [06:52<01:21,  1.57it/s]Epoch 2/8 | Batch 650/778 | Loss: 0.0542\nEpoch 2/8:  90%|██████████████████████████▉   | 699/778 [07:23<00:50,  1.57it/s]Epoch 2/8 | Batch 700/778 | Loss: 0.1018\nEpoch 2/8:  96%|████████████████████████████▉ | 749/778 [07:55<00:18,  1.57it/s]Epoch 2/8 | Batch 750/778 | Loss: 0.0675\nEpoch 2/8: 100%|██████████████████████████████| 778/778 [08:14<00:00,  1.57it/s]\nValidation: 100%|███████████████████████████████| 98/98 [00:19<00:00,  5.11it/s]\nEpoch 2/8\nTrain loss: 0.1079\nValidation loss: 0.0523\n--------------------------------------------------\nEpoch 3/8:   6%|█▉                             | 49/778 [00:30<07:40,  1.58it/s]Epoch 3/8 | Batch 50/778 | Loss: 0.0908\nEpoch 3/8:  13%|███▉                           | 99/778 [01:02<07:06,  1.59it/s]Epoch 3/8 | Batch 100/778 | Loss: 0.0828\nEpoch 3/8:  19%|█████▋                        | 149/778 [01:33<06:38,  1.58it/s]Epoch 3/8 | Batch 150/778 | Loss: 0.0801\nEpoch 3/8:  26%|███████▋                      | 199/778 [02:05<06:05,  1.58it/s]Epoch 3/8 | Batch 200/778 | Loss: 0.0739\nEpoch 3/8:  32%|█████████▌                    | 249/778 [02:37<05:34,  1.58it/s]Epoch 3/8 | Batch 250/778 | Loss: 0.0789\nEpoch 3/8:  38%|███████████▌                  | 299/778 [03:08<05:04,  1.57it/s]Epoch 3/8 | Batch 300/778 | Loss: 0.0848\nEpoch 3/8:  45%|█████████████▍                | 349/778 [03:40<04:31,  1.58it/s]Epoch 3/8 | Batch 350/778 | Loss: 0.0909\nEpoch 3/8:  51%|███████████████▍              | 399/778 [04:12<03:59,  1.58it/s]Epoch 3/8 | Batch 400/778 | Loss: 0.0904\nEpoch 3/8:  58%|█████████████████▎            | 449/778 [04:44<03:28,  1.58it/s]Epoch 3/8 | Batch 450/778 | Loss: 0.0556\nEpoch 3/8:  64%|███████████████████▏          | 499/778 [05:15<02:56,  1.58it/s]Epoch 3/8 | Batch 500/778 | Loss: 0.0485\nEpoch 3/8:  71%|█████████████████████▏        | 549/778 [05:47<02:24,  1.58it/s]Epoch 3/8 | Batch 550/778 | Loss: 0.0962\nEpoch 3/8:  77%|███████████████████████       | 599/778 [06:19<01:52,  1.59it/s]Epoch 3/8 | Batch 600/778 | Loss: 0.1053\nEpoch 3/8:  83%|█████████████████████████     | 649/778 [06:50<01:21,  1.57it/s]Epoch 3/8 | Batch 650/778 | Loss: 0.0453\nEpoch 3/8:  90%|██████████████████████████▉   | 699/778 [07:22<00:49,  1.58it/s]Epoch 3/8 | Batch 700/778 | Loss: 0.0990\nEpoch 3/8:  96%|████████████████████████████▉ | 749/778 [07:54<00:18,  1.58it/s]Epoch 3/8 | Batch 750/778 | Loss: 0.0445\nEpoch 3/8: 100%|██████████████████████████████| 778/778 [08:12<00:00,  1.58it/s]\nValidation: 100%|███████████████████████████████| 98/98 [00:19<00:00,  5.13it/s]\nEpoch 3/8\nTrain loss: 0.0666\nValidation loss: 0.0341\n--------------------------------------------------\nEpoch 4/8:   6%|█▉                             | 49/778 [00:30<07:46,  1.56it/s]Epoch 4/8 | Batch 50/778 | Loss: 0.0409\nEpoch 4/8:  13%|███▉                           | 99/778 [01:02<07:12,  1.57it/s]Epoch 4/8 | Batch 100/778 | Loss: 0.0406\nEpoch 4/8:  19%|█████▋                        | 149/778 [01:34<06:37,  1.58it/s]Epoch 4/8 | Batch 150/778 | Loss: 0.0699\nEpoch 4/8:  26%|███████▋                      | 199/778 [02:06<06:06,  1.58it/s]Epoch 4/8 | Batch 200/778 | Loss: 0.0798\nEpoch 4/8:  32%|█████████▌                    | 249/778 [02:37<05:36,  1.57it/s]Epoch 4/8 | Batch 250/778 | Loss: 0.0416\nEpoch 4/8:  38%|███████████▌                  | 299/778 [03:09<05:03,  1.58it/s]Epoch 4/8 | Batch 300/778 | Loss: 0.0676\nEpoch 4/8:  45%|█████████████▍                | 349/778 [03:41<04:32,  1.57it/s]Epoch 4/8 | Batch 350/778 | Loss: 0.0403\nEpoch 4/8:  51%|███████████████▍              | 399/778 [04:13<04:01,  1.57it/s]Epoch 4/8 | Batch 400/778 | Loss: 0.0457\nEpoch 4/8:  58%|█████████████████▎            | 449/778 [04:45<03:29,  1.57it/s]Epoch 4/8 | Batch 450/778 | Loss: 0.0331\nEpoch 4/8:  64%|███████████████████▏          | 499/778 [05:17<02:56,  1.58it/s]Epoch 4/8 | Batch 500/778 | Loss: 0.0265\nEpoch 4/8:  71%|█████████████████████▏        | 549/778 [05:49<02:26,  1.57it/s]Epoch 4/8 | Batch 550/778 | Loss: 0.0441\nEpoch 4/8:  77%|███████████████████████       | 599/778 [06:20<01:54,  1.56it/s]Epoch 4/8 | Batch 600/778 | Loss: 0.0509\nEpoch 4/8:  83%|█████████████████████████     | 649/778 [06:52<01:22,  1.57it/s]Epoch 4/8 | Batch 650/778 | Loss: 0.0435\nEpoch 4/8:  90%|██████████████████████████▉   | 699/778 [07:24<00:50,  1.56it/s]Epoch 4/8 | Batch 700/778 | Loss: 0.0360\nEpoch 4/8:  96%|████████████████████████████▉ | 749/778 [07:56<00:18,  1.57it/s]Epoch 4/8 | Batch 750/778 | Loss: 0.0491\nEpoch 4/8: 100%|██████████████████████████████| 778/778 [08:14<00:00,  1.57it/s]\nValidation: 100%|███████████████████████████████| 98/98 [00:19<00:00,  5.12it/s]\nEpoch 4/8\nTrain loss: 0.0467\nValidation loss: 0.0224\n--------------------------------------------------\nEpoch 5/8:   6%|█▉                             | 49/778 [00:30<07:45,  1.57it/s]Epoch 5/8 | Batch 50/778 | Loss: 0.0426\nEpoch 5/8:  13%|███▉                           | 99/778 [01:02<07:11,  1.57it/s]Epoch 5/8 | Batch 100/778 | Loss: 0.0482\nEpoch 5/8:  19%|█████▋                        | 149/778 [01:34<06:39,  1.58it/s]Epoch 5/8 | Batch 150/778 | Loss: 0.0493\nEpoch 5/8:  26%|███████▋                      | 199/778 [02:06<06:05,  1.58it/s]Epoch 5/8 | Batch 200/778 | Loss: 0.0328\nEpoch 5/8:  32%|█████████▌                    | 249/778 [02:37<05:33,  1.58it/s]Epoch 5/8 | Batch 250/778 | Loss: 0.0348\nEpoch 5/8:  38%|███████████▌                  | 299/778 [03:09<05:04,  1.57it/s]Epoch 5/8 | Batch 300/778 | Loss: 0.0341\nEpoch 5/8:  45%|█████████████▍                | 349/778 [03:41<04:33,  1.57it/s]Epoch 5/8 | Batch 350/778 | Loss: 0.0315\nEpoch 5/8:  51%|███████████████▍              | 399/778 [04:13<04:01,  1.57it/s]Epoch 5/8 | Batch 400/778 | Loss: 0.0407\nEpoch 5/8:  58%|█████████████████▎            | 449/778 [04:44<03:29,  1.57it/s]Epoch 5/8 | Batch 450/778 | Loss: 0.0292\nEpoch 5/8:  64%|███████████████████▏          | 499/778 [05:16<02:57,  1.57it/s]Epoch 5/8 | Batch 500/778 | Loss: 0.0304\nEpoch 5/8:  71%|█████████████████████▏        | 549/778 [05:48<02:25,  1.58it/s]Epoch 5/8 | Batch 550/778 | Loss: 0.0453\nEpoch 5/8:  77%|███████████████████████       | 599/778 [06:19<01:54,  1.57it/s]Epoch 5/8 | Batch 600/778 | Loss: 0.0349\nEpoch 5/8:  83%|█████████████████████████     | 649/778 [06:51<01:21,  1.57it/s]Epoch 5/8 | Batch 650/778 | Loss: 0.0365\nEpoch 5/8:  90%|██████████████████████████▉   | 699/778 [07:23<00:50,  1.57it/s]Epoch 5/8 | Batch 700/778 | Loss: 0.0237\nEpoch 5/8:  96%|████████████████████████████▉ | 749/778 [07:55<00:18,  1.59it/s]Epoch 5/8 | Batch 750/778 | Loss: 0.0372\nEpoch 5/8: 100%|██████████████████████████████| 778/778 [08:13<00:00,  1.58it/s]\nValidation: 100%|███████████████████████████████| 98/98 [00:19<00:00,  5.12it/s]\nEpoch 5/8\nTrain loss: 0.0339\nValidation loss: 0.0151\n--------------------------------------------------\nEpoch 6/8:   6%|█▉                             | 49/778 [00:30<07:39,  1.58it/s]Epoch 6/8 | Batch 50/778 | Loss: 0.0240\nEpoch 6/8:  13%|███▉                           | 99/778 [01:02<07:09,  1.58it/s]Epoch 6/8 | Batch 100/778 | Loss: 0.0338\nEpoch 6/8:  19%|█████▋                        | 149/778 [01:33<06:36,  1.59it/s]Epoch 6/8 | Batch 150/778 | Loss: 0.0306\nEpoch 6/8:  26%|███████▋                      | 199/778 [02:05<06:05,  1.58it/s]Epoch 6/8 | Batch 200/778 | Loss: 0.0275\nEpoch 6/8:  32%|█████████▌                    | 249/778 [02:36<05:33,  1.59it/s]Epoch 6/8 | Batch 250/778 | Loss: 0.0196\nEpoch 6/8:  38%|███████████▌                  | 299/778 [03:08<05:04,  1.57it/s]Epoch 6/8 | Batch 300/778 | Loss: 0.0204\nEpoch 6/8:  45%|█████████████▍                | 349/778 [03:40<04:34,  1.56it/s]Epoch 6/8 | Batch 350/778 | Loss: 0.0242\nEpoch 6/8:  51%|███████████████▍              | 399/778 [04:12<03:59,  1.59it/s]Epoch 6/8 | Batch 400/778 | Loss: 0.0193\nEpoch 6/8:  58%|█████████████████▎            | 449/778 [04:43<03:27,  1.59it/s]Epoch 6/8 | Batch 450/778 | Loss: 0.0188\nEpoch 6/8:  64%|███████████████████▏          | 499/778 [05:15<02:57,  1.57it/s]Epoch 6/8 | Batch 500/778 | Loss: 0.0117\nEpoch 6/8:  71%|█████████████████████▏        | 549/778 [05:46<02:26,  1.57it/s]Epoch 6/8 | Batch 550/778 | Loss: 0.0185\nEpoch 6/8:  77%|███████████████████████       | 599/778 [06:18<01:53,  1.58it/s]Epoch 6/8 | Batch 600/778 | Loss: 0.0384\nEpoch 6/8:  83%|█████████████████████████     | 649/778 [06:50<01:21,  1.59it/s]Epoch 6/8 | Batch 650/778 | Loss: 0.0223\nEpoch 6/8:  90%|██████████████████████████▉   | 699/778 [07:21<00:49,  1.59it/s]Epoch 6/8 | Batch 700/778 | Loss: 0.0331\nEpoch 6/8:  96%|████████████████████████████▉ | 749/778 [07:53<00:18,  1.58it/s]Epoch 6/8 | Batch 750/778 | Loss: 0.0284\nEpoch 6/8: 100%|██████████████████████████████| 778/778 [08:11<00:00,  1.58it/s]\nValidation: 100%|███████████████████████████████| 98/98 [00:19<00:00,  5.14it/s]\nEpoch 6/8\nTrain loss: 0.0251\nValidation loss: 0.0115\n--------------------------------------------------\nEpoch 7/8:   6%|█▉                             | 49/778 [00:30<07:41,  1.58it/s]Epoch 7/8 | Batch 50/778 | Loss: 0.0235\nEpoch 7/8:  13%|███▉                           | 99/778 [01:02<07:09,  1.58it/s]Epoch 7/8 | Batch 100/778 | Loss: 0.0101\nEpoch 7/8:  19%|█████▋                        | 149/778 [01:34<06:38,  1.58it/s]Epoch 7/8 | Batch 150/778 | Loss: 0.0282\nEpoch 7/8:  26%|███████▋                      | 199/778 [02:05<06:03,  1.59it/s]Epoch 7/8 | Batch 200/778 | Loss: 0.0149\nEpoch 7/8:  32%|█████████▌                    | 249/778 [02:37<05:35,  1.58it/s]Epoch 7/8 | Batch 250/778 | Loss: 0.0140\nEpoch 7/8:  38%|███████████▌                  | 299/778 [03:08<05:00,  1.59it/s]Epoch 7/8 | Batch 300/778 | Loss: 0.0282\nEpoch 7/8:  45%|█████████████▍                | 349/778 [03:40<04:32,  1.58it/s]Epoch 7/8 | Batch 350/778 | Loss: 0.0241\nEpoch 7/8:  51%|███████████████▍              | 399/778 [04:11<04:01,  1.57it/s]Epoch 7/8 | Batch 400/778 | Loss: 0.0102\nEpoch 7/8:  58%|█████████████████▎            | 449/778 [04:43<03:28,  1.58it/s]Epoch 7/8 | Batch 450/778 | Loss: 0.0104\nEpoch 7/8:  64%|███████████████████▏          | 499/778 [05:15<02:56,  1.58it/s]Epoch 7/8 | Batch 500/778 | Loss: 0.0161\nEpoch 7/8:  71%|█████████████████████▏        | 549/778 [05:46<02:24,  1.58it/s]Epoch 7/8 | Batch 550/778 | Loss: 0.0181\nEpoch 7/8:  77%|███████████████████████       | 599/778 [06:18<01:53,  1.58it/s]Epoch 7/8 | Batch 600/778 | Loss: 0.0200\nEpoch 7/8:  83%|█████████████████████████     | 649/778 [06:50<01:22,  1.57it/s]Epoch 7/8 | Batch 650/778 | Loss: 0.0177\nEpoch 7/8:  90%|██████████████████████████▉   | 699/778 [07:22<00:50,  1.56it/s]Epoch 7/8 | Batch 700/778 | Loss: 0.0152\nEpoch 7/8:  96%|████████████████████████████▉ | 749/778 [07:53<00:18,  1.57it/s]Epoch 7/8 | Batch 750/778 | Loss: 0.0150\nEpoch 7/8: 100%|██████████████████████████████| 778/778 [08:12<00:00,  1.58it/s]\nValidation: 100%|███████████████████████████████| 98/98 [00:19<00:00,  5.13it/s]\nEpoch 7/8\nTrain loss: 0.0195\nValidation loss: 0.0084\n--------------------------------------------------\nEpoch 8/8:   6%|█▉                             | 49/778 [00:31<07:45,  1.57it/s]Epoch 8/8 | Batch 50/778 | Loss: 0.0200\nEpoch 8/8:  13%|███▉                           | 99/778 [01:03<07:14,  1.56it/s]Epoch 8/8 | Batch 100/778 | Loss: 0.0145\nEpoch 8/8:  19%|█████▋                        | 149/778 [01:35<06:42,  1.56it/s]Epoch 8/8 | Batch 150/778 | Loss: 0.0076\nEpoch 8/8:  26%|███████▋                      | 199/778 [02:07<06:10,  1.56it/s]Epoch 8/8 | Batch 200/778 | Loss: 0.0145\nEpoch 8/8:  32%|█████████▌                    | 249/778 [02:39<05:39,  1.56it/s]Epoch 8/8 | Batch 250/778 | Loss: 0.0119\nEpoch 8/8:  38%|███████████▌                  | 299/778 [03:11<05:06,  1.56it/s]Epoch 8/8 | Batch 300/778 | Loss: 0.0149\nEpoch 8/8:  45%|█████████████▍                | 349/778 [03:43<04:34,  1.56it/s]Epoch 8/8 | Batch 350/778 | Loss: 0.0153\nEpoch 8/8:  51%|███████████████▍              | 399/778 [04:15<04:02,  1.56it/s]Epoch 8/8 | Batch 400/778 | Loss: 0.0101\nEpoch 8/8:  58%|█████████████████▎            | 449/778 [04:47<03:29,  1.57it/s]Epoch 8/8 | Batch 450/778 | Loss: 0.0143\nEpoch 8/8:  64%|███████████████████▏          | 499/778 [05:19<02:58,  1.56it/s]Epoch 8/8 | Batch 500/778 | Loss: 0.0147\nEpoch 8/8:  71%|█████████████████████▏        | 549/778 [05:51<02:26,  1.56it/s]Epoch 8/8 | Batch 550/778 | Loss: 0.0163\nEpoch 8/8:  77%|███████████████████████       | 599/778 [06:23<01:54,  1.56it/s]Epoch 8/8 | Batch 600/778 | Loss: 0.0140\nEpoch 8/8:  83%|█████████████████████████     | 649/778 [06:55<01:22,  1.57it/s]Epoch 8/8 | Batch 650/778 | Loss: 0.0086\nEpoch 8/8:  90%|██████████████████████████▉   | 699/778 [07:27<00:50,  1.56it/s]Epoch 8/8 | Batch 700/778 | Loss: 0.0087\nEpoch 8/8:  96%|████████████████████████████▉ | 749/778 [07:59<00:18,  1.56it/s]Epoch 8/8 | Batch 750/778 | Loss: 0.0162\nEpoch 8/8: 100%|██████████████████████████████| 778/778 [08:17<00:00,  1.56it/s]\nValidation: 100%|███████████████████████████████| 98/98 [00:19<00:00,  5.12it/s]\nEpoch 8/8\nTrain loss: 0.0149\nValidation loss: 0.0057\n--------------------------------------------------\nFigure(1000x600)\nModel saved successfully!\nEvaluating:  19%|██████                         | 19/98 [00:53<03:42,  2.82s/it]Evaluated 20/98 batches\nEvaluating:  40%|████████████▎                  | 39/98 [01:50<02:46,  2.82s/it]Evaluated 40/98 batches\nEvaluating:  60%|██████████████████▋            | 59/98 [02:47<01:58,  3.05s/it]Evaluated 60/98 batches\nEvaluating:  81%|████████████████████████▉      | 79/98 [03:47<00:49,  2.61s/it]Evaluated 80/98 batches\nEvaluating: 100%|███████████████████████████████| 98/98 [04:43<00:00,  2.89s/it]\nTest sequence accuracy: 0.4859\nTest token accuracy: 0.5268\n\nSample predictions vs targets:\n\nExample 1:\nPrediction: - 2/81 * e ^ 4 * s_11 * ( 64 * m_t ^ 2 + ( - 16 ) * s_12 ) * ( m_t ^ 2 + - s_11 + 2 * s_13 + - reg_prop ) ^ ( - 2 ) + - 128/81 * i * e ^ 2 * m_t * ( i * e ^ 2 * m_t * ( s_11 + - s_12 ) / ( m_t ^ 2 + - s_11 + 2 * s_13 + - reg_prop ) + - i * e ^ 2 * m_...\nTarget: 4 * e ^ 4 * s_13 * s_23 * ( m_t ^ 2 + - s_22 + 2 * s_23 + - reg_prop ) ^ ( - 2 ) + 8 * i * e ^ 2 * m_t * ( i * e ^ 2 * m_t * ( m_t ^ 2 + - 1/4 * s_12 ) / ( m_t ^ 2 + - s_22 + 2 * s_23 + - reg_prop ) + - i * e ^ 2 * m_t * ( s_13 + - s_23 ) / ( m_t ^ 2...\nCorrect: False\n\nExample 2:\nPrediction: 16/81 * e ^ 4 * ( 16 * m_u ^ 2 * s_22 + ( - 4 ) * s_13 * s_22 + 8 * s_12 * s_23 ) * ( s_22 + ( - 2 ) * s_23 + reg_prop ) ^ ( - 2 ) + - 16/81 * i * e ^ 2 * ( i * e ^ 2 * m_u ^ 2 * ( m_u ^ 2 + - 1/2 * s_13 ) / ( s_22 + ( - 2 ) * s_23 + reg_prop ) + 1/2...\nTarget: 16/81 * e ^ 4 * ( 16 * m_u ^ 2 * s_22 + ( - 4 ) * s_13 * s_22 + 8 * s_12 * s_23 ) * ( s_22 + ( - 2 ) * s_23 + reg_prop ) ^ ( - 2 ) + - 256/81 * i * e ^ 2 * ( i * e ^ 2 * m_u ^ 2 * ( m_u ^ 2 + - 1/2 * s_13 ) / ( s_22 + ( - 2 ) * s_23 + reg_prop ) + 1/...\nCorrect: False\n\nExample 3:\nPrediction: 4/9 * e ^ 4 * ( 16 * m_c ^ 2 * m_mu ^ 2 + 8 * m_c ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_mu ^ 2 * s_34 ) * ( s_11 + 2 * s_12 + s_22 + reg_prop ) ^ ( - 2 )\nTarget: 4/9 * e ^ 4 * ( 16 * m_c ^ 2 * m_mu ^ 2 + 8 * m_c ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_mu ^ 2 * s_34 ) * ( s_11 + 2 * s_12 + s_22 + reg_prop ) ^ ( - 2 )\nCorrect: True\n\nExample 4:\nPrediction: 32/81 * e ^ 4 * s_23 * s_24 * ( s_23 + - 1/2 * reg_prop ) ^ ( - 2 ) + - 1/324 * i * e ^ 2 * ( i * e ^ 2 * m_u ^ 2 * ( 16 * s_23 + 8 * s_24 ) / ( s_23 + - 1/2 * reg_prop ) + ( - 16 ) * i * e ^ 2 * m_u ^ 2 * ( m_u ^ 2 + 1/2 * s_34 ) / ( s_23 + - 1/2 * ...\nTarget: 32/81 * e ^ 4 * s_23 * s_24 * ( s_23 + - 1/2 * reg_prop ) ^ ( - 2 ) + - 4/81 * i * e ^ 2 * ( i * e ^ 2 * m_u ^ 2 * ( 16 * s_23 + 8 * s_24 ) / ( s_23 + - 1/2 * reg_prop ) + ( - 16 ) * i * e ^ 2 * m_u ^ 2 * ( m_u ^ 2 + 1/2 * s_34 ) / ( s_23 + - 1/2 * r...\nCorrect: False\n\nExample 5:\nPrediction: e ^ 4 * ( 16 * m_t ^ 2 * s_22 + ( - 4 ) * s_13 * s_22 + 8 * s_12 * s_23 ) * ( s_22 + ( - 2 ) * s_23 + reg_prop ) ^ ( - 2 ) + - 256/81 * i * e ^ 2 * ( i * e ^ 2 * m_t ^ 2 * ( m_t ^ 2 + - 1/2 * s_13 ) / ( s_22 + ( - 2 ) * s_23 + reg_prop ) + 1/2 * i * ...\nTarget: e ^ 4 * ( 16 * m_t ^ 2 * s_22 + ( - 4 ) * s_13 * s_22 + 8 * s_12 * s_23 ) * ( s_22 + ( - 2 ) * s_23 + reg_prop ) ^ ( - 2 ) + ( - 16 ) * i * e ^ 2 * ( i * e ^ 2 * m_t ^ 2 * ( m_t ^ 2 + - 1/2 * s_13 ) / ( s_22 + ( - 2 ) * s_23 + reg_prop ) + 1/2 * i * ...\nCorrect: False\n\nExample 6:\nPrediction: 2/81 * e ^ 4 * s_23 * s_24 * ( s_23 + - 1/2 * reg_prop ) ^ ( - 2 ) + - 1/324 * i * e ^ 2 * ( i * e ^ 2 * m_s ^ 2 * ( 16 * s_23 + 8 * s_24 ) / ( s_23 + - 1/2 * reg_prop ) + ( - 16 ) * i * e ^ 2 * m_s ^ 2 * ( m_s ^ 2 + 1/2 * s_34 ) / ( s_23 + - 1/2 * r...\nTarget: 2/81 * e ^ 4 * s_23 * s_24 * ( s_23 + - 1/2 * reg_prop ) ^ ( - 2 ) + - 1/324 * i * e ^ 2 * ( i * e ^ 2 * m_s ^ 2 * ( 16 * s_23 + 8 * s_24 ) / ( s_23 + - 1/2 * reg_prop ) + ( - 16 ) * i * e ^ 2 * m_s ^ 2 * ( m_s ^ 2 + 1/2 * s_34 ) / ( s_23 + - 1/2 * r...\nCorrect: True\n\nExample 7:\nPrediction: 1/81 * e ^ 4 * s_14 * s_24 * ( s_13 + - 1/2 * s_33 + - 1/2 * reg_prop ) ^ ( - 2 ) + 2/81 * i * e ^ 2 * ( i * e ^ 2 * m_s ^ 2 * ( m_s ^ 2 + 1/2 * s_12 ) / ( s_13 + - 1/2 * s_33 + - 1/2 * reg_prop ) + - 1/16 * i * e ^ 2 * m_s ^ 2 * ( 16 * s_14 + 8 * s_...\nTarget: 1/81 * e ^ 4 * ( s_13 * s_23 + ( - 2 ) * m_s ^ 2 * s_33 + - 1/2 * s_12 * s_33 ) * ( s_13 + - 1/2 * s_33 + - 1/2 * reg_prop ) ^ ( - 2 ) + 2/81 * i * e ^ 2 * ( i * e ^ 2 * m_s ^ 2 * ( m_s ^ 2 + 1/2 * s_12 ) / ( s_13 + - 1/2 * s_33 + - 1/2 * reg_prop ) ...\nCorrect: False\n\nExample 8:\nPrediction: 1/36 * e ^ 4 * ( 16 * m_s ^ 2 * m_t ^ 2 + 8 * m_s ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_t ^ 2 * s_34 ) * ( m_t ^ 2 + s_12 + 1/2 * reg_prop ) ^ ( - 2 )\nTarget: 1/36 * e ^ 4 * ( 16 * m_s ^ 2 * m_t ^ 2 + 8 * m_s ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_t ^ 2 * s_34 ) * ( m_t ^ 2 + s_12 + 1/2 * reg_prop ) ^ ( - 2 )\nCorrect: True\n\nExample 9:\nPrediction: e ^ 4 * s_13 * s_23 * ( m_mu ^ 2 + - s_22 + 2 * s_23 + - reg_prop ) ^ ( - 2 ) + 8 * i * e ^ 2 * m_mu * ( i * e ^ 2 * m_mu * ( m_mu ^ 2 + - 1/4 * s_12 ) / ( m_mu ^ 2 + - s_22 + 2 * s_23 + - reg_prop ) + i * e ^ 2 * m_mu * ( s_12 + - s_22 ) / ( m_mu ^ ...\nTarget: 4 * e ^ 4 * ( s_13 * s_23 + ( - 2 ) * m_mu ^ 2 * s_33 + - 1/2 * s_12 * s_33 ) * ( m_mu ^ 2 + - s_22 + 2 * s_23 + - s_33 + - reg_prop ) ^ ( - 2 ) + 8 * i * e ^ 2 * m_mu * ( i * e ^ 2 * m_mu * ( m_mu ^ 2 + - 1/4 * s_12 ) / ( m_mu ^ 2 + - s_22 + 2 * s_2...\nCorrect: False\n\nExample 10:\nPrediction: 1/9 * e ^ 4 * ( 16 * m_d ^ 2 * m_e ^ 2 + ( - 8 ) * m_d ^ 2 * s_13 + 8 * s_14 * s_23 + ( - 8 ) * m_e ^ 2 * s_24 + 8 * s_12 * s_34 ) * ( m_e ^ 2 + ( - 2 ) * s_13 + s_33 + reg_prop ) ^ ( - 2 )\nTarget: 1/9 * e ^ 4 * ( 16 * m_d ^ 2 * m_e ^ 2 + ( - 8 ) * m_d ^ 2 * s_13 + 8 * s_14 * s_23 + ( - 8 ) * m_e ^ 2 * s_24 + 8 * s_12 * s_34 ) * ( m_e ^ 2 + ( - 2 ) * s_13 + s_33 + reg_prop ) ^ ( - 2 )\nCorrect: True\n\nExample 11:\nPrediction: 16/81 * e ^ 4 * ( 16 * m_u ^ 2 * m_tt ^ 2 + 8 * m_u ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_tt ^ 2 * s_34 ) * ( m_tt ^ 2 + s_11 + 2 * s_12 + reg_prop ) ^ ( - 2 )\nTarget: 16/81 * e ^ 4 * ( 16 * m_u ^ 2 * m_tt ^ 2 + 8 * m_u ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_tt ^ 2 * s_34 ) * ( m_tt ^ 2 + s_11 + 2 * s_12 + reg_prop ) ^ ( - 2 )\nCorrect: True\n\nExample 12:\nPrediction: - 2/81 * e ^ 4 * s_11 * ( 64 * m_t ^ 2 + ( - 16 ) * s_12 ) * ( m_t ^ 2 + - s_11 + 2 * s_13 + - reg_prop ) ^ ( - 2 ) + ( - 8 ) * i * e ^ 2 * m_t * ( i * e ^ 2 * m_t * ( s_11 + - s_12 ) / ( m_t ^ 2 + - s_11 + 2 * s_13 + - reg_prop ) + - i * e ^ 2 * m_t...\nTarget: 4 * e ^ 4 * ( s_13 * s_23 + ( - 2 ) * m_t ^ 2 * s_33 + - 1/2 * s_12 * s_33 ) * ( m_t ^ 2 + - s_22 + 2 * s_23 + - s_33 + - reg_prop ) ^ ( - 2 ) + 8 * i * e ^ 2 * m_t * ( i * e ^ 2 * m_t * ( m_t ^ 2 + - 1/4 * s_12 ) / ( m_t ^ 2 + - s_22 + 2 * s_23 + - ...\nCorrect: False\n\nExample 13:\nPrediction: 1/9 * e ^ 4 * ( 16 * m_e ^ 2 * m_s ^ 2 + 8 * m_e ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_s ^ 2 * s_34 ) * ( m_s ^ 2 + 2 * s_12 + s_22 + reg_prop ) ^ ( - 2 )\nTarget: 1/9 * e ^ 4 * ( 16 * m_e ^ 2 * m_s ^ 2 + 8 * m_e ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_s ^ 2 * s_34 ) * ( m_s ^ 2 + 2 * s_12 + s_22 + reg_prop ) ^ ( - 2 )\nCorrect: True\n\nExample 14:\nPrediction: - 1/648 * e ^ 4 * s_11 * ( 64 * m_d ^ 2 + ( - 16 ) * s_12 ) * ( m_d ^ 2 + - s_11 + 2 * s_13 + - s_33 + - reg_prop ) ^ ( - 2 ) + - 8/81 * i * e ^ 2 * m_d * ( i * e ^ 2 * m_d * ( s_11 + - s_12 ) / ( m_d ^ 2 + - s_11 + 2 * s_13 + - s_33 + - reg_prop ) +...\nTarget: 16/81 * e ^ 4 * m_d ^ 2 * ( m_d ^ 2 + 1/4 * s_13 ) * ( m_d ^ 2 + - s_22 + 2 * s_23 + - s_33 + - reg_prop ) ^ ( - 2 ) + - 1/324 * i * e ^ 2 * ( i * e ^ 2 * ( 64 * m_d ^ 2 + 16 * s_13 ) * s_33 / ( m_d ^ 2 + - s_22 + 2 * s_23 + - s_33 + - reg_prop ) + (...\nCorrect: False\n\nExample 15:\nPrediction: 4/9 * e ^ 4 * ( 16 * m_mu ^ 2 * m_tt ^ 2 + 8 * m_mu ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_tt ^ 2 * s_34 ) * ( m_tt ^ 2 + 2 * s_12 + s_22 + reg_prop ) ^ ( - 2 )\nTarget: 4/9 * e ^ 4 * ( 16 * m_mu ^ 2 * m_tt ^ 2 + 8 * m_mu ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_tt ^ 2 * s_34 ) * ( m_tt ^ 2 + 2 * s_12 + s_22 + reg_prop ) ^ ( - 2 )\nCorrect: True\n\nExample 16:\nPrediction: 1/36 * e ^ 4 * ( 16 * m_s ^ 2 * m_mu ^ 2 + 8 * m_s ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_mu ^ 2 * s_34 ) * ( m_mu ^ 2 + s_12 + 1/2 * reg_prop ) ^ ( - 2 )\nTarget: 1/36 * e ^ 4 * ( 16 * m_s ^ 2 * m_mu ^ 2 + 8 * m_s ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_mu ^ 2 * s_34 ) * ( m_mu ^ 2 + s_12 + 1/2 * reg_prop ) ^ ( - 2 )\nCorrect: True\n\nExample 17:\nPrediction: e ^ 4 * ( ( - 16 ) * m_mu ^ 2 * s_22 + 8 * s_23 * s_24 + ( - 4 ) * s_22 * s_34 ) * ( s_22 + ( - 2 ) * s_23 + reg_prop ) ^ ( - 2 ) + - i * e ^ 2 * ( i * e ^ 2 * m_mu ^ 2 * ( 16 * s_23 + 8 * s_24 ) / ( s_22 + ( - 2 ) * s_23 + reg_prop ) + ( - 16 ) * i ...\nTarget: ( - 16 ) * e ^ 4 * m_mu ^ 2 * ( m_mu ^ 2 + 1/2 * s_34 ) * ( s_22 + ( - 2 ) * s_23 + reg_prop ) ^ ( - 2 ) + - i * e ^ 2 * ( i * e ^ 2 * m_mu ^ 2 * ( 16 * s_23 + 8 * s_24 ) / ( s_22 + ( - 2 ) * s_23 + reg_prop ) + i * e ^ 2 * ( ( - 16 ) * m_mu ^ 2 * s_...\nCorrect: False\n\nExample 18:\nPrediction: - 2/81 * e ^ 4 * s_11 * ( 64 * m_mu ^ 2 + ( - 16 ) * s_12 ) * ( m_mu ^ 2 + - s_11 + 2 * s_13 + - s_33 + - reg_prop ) ^ ( - 2 ) + ( - 8 ) * i * e ^ 2 * m_mu * ( i * e ^ 2 * m_mu * ( s_11 + - s_12 ) / ( m_mu ^ 2 + - s_11 + 2 * s_13 + - s_33 + - reg_pro...\nTarget: 16 * e ^ 4 * m_mu ^ 2 * ( m_mu ^ 2 + 1/4 * s_13 ) * ( m_mu ^ 2 + - s_22 + 2 * s_23 + - s_33 + - reg_prop ) ^ ( - 2 ) + - 1/4 * i * e ^ 2 * ( i * e ^ 2 * ( 64 * m_mu ^ 2 + 16 * s_13 ) * s_33 / ( m_mu ^ 2 + - s_22 + 2 * s_23 + - s_33 + - reg_prop ) + (...\nCorrect: False\n\nExample 19:\nPrediction: - 1/648 * e ^ 4 * s_11 * ( 64 * m_s ^ 2 + ( - 16 ) * s_12 ) * ( m_s ^ 2 + - s_11 + 2 * s_13 + - reg_prop ) ^ ( - 2 ) + - 8/81 * i * e ^ 2 * m_s * ( i * e ^ 2 * m_s * ( s_11 + - s_12 ) / ( m_s ^ 2 + - s_11 + 2 * s_13 + - reg_prop ) + - i * e ^ 2 * m_s...\nTarget: 4/81 * e ^ 4 * s_13 * s_23 * ( m_s ^ 2 + - s_22 + 2 * s_23 + - reg_prop ) ^ ( - 2 ) + 8/81 * i * e ^ 2 * m_s * ( i * e ^ 2 * m_s * ( m_s ^ 2 + - 1/4 * s_12 ) / ( m_s ^ 2 + - s_22 + 2 * s_23 + - reg_prop ) + i * e ^ 2 * m_s * ( s_12 + - s_22 ) / ( m_s...\nCorrect: False\n\nExample 20:\nPrediction: 1/9 * e ^ 4 * ( 16 * m_s ^ 2 * m_mu ^ 2 + 8 * m_mu ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_s ^ 2 * s_34 ) * ( m_s ^ 2 + s_11 + 2 * s_12 + reg_prop ) ^ ( - 2 )\nTarget: 1/9 * e ^ 4 * ( 16 * m_s ^ 2 * m_mu ^ 2 + 8 * m_mu ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_s ^ 2 * s_34 ) * ( m_s ^ 2 + s_11 + 2 * s_12 + reg_prop ) ^ ( - 2 )\nCorrect: True\n\nExample 21:\nPrediction: e ^ 4 * ( s_13 * s_23 + ( - 2 ) * m_mu ^ 2 * s_33 + - 1/2 * s_12 * s_33 ) * ( s_23 + - 1/2 * s_33 + - 1/2 * reg_prop ) ^ ( - 2 ) + 2/81 * i * e ^ 2 * ( i * e ^ 2 * m_mu ^ 2 * ( m_mu ^ 2 + 1/2 * s_12 ) / ( s_23 + - 1/2 * s_33 + - 1/2 * reg_prop ) + - ...\nTarget: e ^ 4 * s_13 * s_23 * ( s_23 + - 1/2 * reg_prop ) ^ ( - 2 ) + 2 * i * e ^ 2 * ( i * e ^ 2 * m_mu ^ 2 * ( m_mu ^ 2 + 1/2 * s_12 ) / ( s_23 + - 1/2 * reg_prop ) + - 1/2 * i * e ^ 2 * m_mu ^ 2 * ( s_13 + 2 * s_23 ) / ( s_23 + - 1/2 * reg_prop ) ) / ( s_...\nCorrect: False\n\nExample 22:\nPrediction: 4/9 * e ^ 4 * ( 16 * m_e ^ 2 * m_tt ^ 2 + 8 * m_tt ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_e ^ 2 * s_34 ) * ( s_11 + 2 * s_12 + s_22 + reg_prop ) ^ ( - 2 )\nTarget: 4/9 * e ^ 4 * ( 16 * m_e ^ 2 * m_tt ^ 2 + 8 * m_tt ^ 2 * s_12 + 8 * s_14 * s_23 + 8 * s_13 * s_24 + 8 * m_e ^ 2 * s_34 ) * ( s_11 + 2 * s_12 + s_22 + reg_prop ) ^ ( - 2 )\nCorrect: True\n\nExample 23:\nPrediction: - 4/81 * e ^ 4 * s_33 * ( 64 * m_c ^ 2 + ( - 16 ) * s_34 ) * ( m_c ^ 2 + - s_11 + 2 * s_13 + - s_33 + - reg_prop ) ^ ( - 2 ) + 16/81 * i * e ^ 2 * m_c * ( i * e ^ 2 * m_c * ( s_13 + - s_14 ) / ( m_c ^ 2 + - s_11 + 2 * s_13 + - s_33 + - reg_prop ) + -...\nTarget: - 4/81 * e ^ 4 * s_33 * ( 64 * m_c ^ 2 + ( - 16 ) * s_34 ) * ( m_c ^ 2 + - s_11 + 2 * s_13 + - s_33 + - reg_prop ) ^ ( - 2 ) + 256/81 * i * e ^ 2 * m_c * ( i * e ^ 2 * m_c * ( s_13 + - s_14 ) / ( m_c ^ 2 + - s_11 + 2 * s_13 + - s_33 + - reg_prop ) + ...\nCorrect: False\n\nExample 24:\nPrediction: 1/81 * e ^ 4 * ( 16 * m_c ^ 2 * m_s ^ 2 + ( - 8 ) * m_c ^ 2 * s_13 + 8 * s_14 * s_23 + ( - 8 ) * m_s ^ 2 * s_24 + 8 * s_12 * s_34 ) * ( m_s ^ 2 + - s_13 + 1/2 * reg_prop ) ^ ( - 2 )\nTarget: 1/81 * e ^ 4 * ( 16 * m_c ^ 2 * m_s ^ 2 + ( - 8 ) * m_c ^ 2 * s_13 + 8 * s_14 * s_23 + ( - 8 ) * m_s ^ 2 * s_24 + 8 * s_12 * s_34 ) * ( m_s ^ 2 + - s_13 + 1/2 * reg_prop ) ^ ( - 2 )\nCorrect: True\n\nExample 25:\nPrediction: 2/81 * e ^ 4 * s_23 * s_24 * ( s_23 + - 1/2 * reg_prop ) ^ ( - 2 ) + - 1/324 * i * e ^ 2 * ( i * e ^ 2 * m_s ^ 2 * ( s_23 + 2 * s_24 ) / ( s_23 + - 1/2 * reg_prop ) + ( - 2 ) * i * e ^ 2 * m_s ^ 2 * ( m_s ^ 2 + 1/2 * s_34 ) / ( s_23 + - 1/2 * reg_pro...\nTarget: 1/324 * e ^ 4 * ( ( - 16 ) * m_s ^ 2 * s_22 + 8 * s_23 * s_24 + ( - 4 ) * s_22 * s_34 ) * ( s_13 + - 1/2 * reg_prop ) ^ ( - 2 ) + - 2/81 * i * e ^ 2 * ( i * e ^ 2 * m_s ^ 2 * ( s_23 + 2 * s_24 ) / ( s_13 + - 1/2 * reg_prop ) + ( - 2 ) * i * e ^ 2 * m...\nCorrect: False\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!zip -r t5_KAT_model.zip t5_KAT_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T17:20:51.186140Z","iopub.execute_input":"2025-04-05T17:20:51.186464Z","iopub.status.idle":"2025-04-05T17:21:00.829706Z","shell.execute_reply.started":"2025-04-05T17:20:51.186439Z","shell.execute_reply":"2025-04-05T17:21:00.828712Z"}},"outputs":[{"name":"stdout","text":"  adding: t5_KAT_model/ (stored 0%)\n  adding: t5_KAT_model/training_history.png (deflated 12%)\n  adding: t5_KAT_model/amplitude_model.pth (deflated 7%)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}